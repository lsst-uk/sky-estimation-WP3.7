#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Package for doing a basic data reduction on the fakes images generated by
insert_fakes.py, including sky-subtraction and image coaddition.
"""


import numpy as np
from scipy import ndimage
from scipy.stats import sigmaclip
from astropy.io import fits
from astropy.modeling.models import Legendre2D
from astropy.modeling.fitting import LevMarLSQFitter
from skimage.restoration import inpaint
import cv2
import glob

from fakes import insert_fakes as insfk


def makeHduList(image, header=None):
    '''
    Creates an HDUList object from an image array and a FITS header object
        Parameters
        ----------
        image : `numpy.ndarray`
            Image data array
        header : `astropy.io.fits.Header`
            Header object to be included with the data array.
            Defaults to None

        Returns
        -------
        hduList : `astropy.io.fits.HDUList`
            Image with header HDUList object (writable)
    '''
    hdu = fits.PrimaryHDU(image, header=header)
    hduList = fits.HDUList([hdu])

    return hduList


def writeImHead(imageData, imageHeader, fileName):
    '''
    Writes an image to the hard drive, with accompanying FITS header.

        Parameters
        ----------
        imageData : `numpy.ndarray`
            Image data array
        imageHeader : `astropy.io.fits.Header`
            Header object to be included with the data array
        fileName : `string
            Full or partial path at which to write the new image

        Returns
        -------
        None.

    NOTE: auto-overwrites previous files with that name!

    '''
    hduList = makeHduList(imageData, imageHeader)
    hduList.writeto(fileName, overwrite=True)


def getFnames(dirNm, prefix='fakes', prefixNoNoise='onlymodels'):
    '''
    Makes a list of file names for images to be processed
        Parameters
        ----------
        dirNm : `string`
            Directory in which to find the images (excluding trailing /)
        prefix : `string`
            Common image name prefix prior to wildcard

        Returns
        -------
        imList : `list`
            List of filenames and associated directory
        imListNoNoise : `list`
            List of associated noiseless image filenames
    '''
    imList = glob.glob(dirNm + '/' + prefix + '*.fits')
    inds = [int(i[i.find(prefix)+len(prefix):-5]) for i in imList]
    idx = np.argsort(inds)
    imList = list(np.array(imList)[idx])
    imListNoNoise = [dirNm + '/' + prefixNoNoise + str(i)
                     + '.fits' for i in np.array(inds)[idx]]

    return imList, imListNoNoise


def makeBlankImage(raCen, decCen, size, pxScale=0.168):
    '''
    Creates a blank image HDU with a WCS
        Parameters
        ----------
        raCen : `float`
            Central pixel reference right ascension, in decimal degrees
        decCen : `float`
            Central pixel reference declination, in decimal degrees
        size : `int`
            Width of blank image in pixels
        pxScale : `float`
            Pixel scale, in arcsec/px, for the blank image

        Returns
        -------
        blankHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Image HDU with given parameters, all zero data values
    '''
    assert (raCen >= 0) & (raCen <= 360), \
        'Invalid RA: use decimal degrees.'
    assert (decCen >= -90) & (decCen <= 90), \
        'Invalid Dec: use decimal degrees.'
    assert size > 0, \
        'Size must be finite and non-zero'
    assert pxScale > 0, \
        'pxScale must be finite and non-zero'
    dimX = size
    dimY = size
    blnkIm = insfk.ImageBuilder(dimX, dimY, raCen, decCen, pxScale, {})
    hdu = fits.PrimaryHDU(blnkIm.image.array, header=blnkIm.w.to_header())
    blankHdu = fits.HDUList([hdu])

    return blankHdu


def binImage(maskedHdu, block=9):
    '''
    Median bins image into block*block pixels.  Assumes masked pixels are NaN.
        Parameters
        ----------
        maskedHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Image to be binned
        block : `int`
            Binning factor in pixels

        Returns
        -------
        binnedHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Binned image, with scaled WCS if applicable
        weight: `numpy.ndarray`
            Weight map, proportional to number of unmasked pixels in each bin
    NOTE: this doesn't allow for higher-order terms like PC3_J, PC4_J, etc.
    '''
    assert block > 0, 'Binning factor must be positive and non-zero'
    assert maskedHdu[0].header['NAXIS1'] == maskedHdu[0].data.shape[1], \
        'Header mismatch or non-existent.  Image needs a header.'
    assert ('PC1_1' in maskedHdu[0].header) \
        | ('CD1_1' in maskedHdu[0].header), \
        'WCS info in header must be in either PCI_J or CDI_J format.'

    # First converting header to CDI_J format if not already there
    keys = ['PC1_1', 'PC1_2', 'PC2_1', 'PC2_2']
    for key in keys:
        if key in maskedHdu[0].header:
            cdKey = 'CD'+key[2:]
            if key[2] == '1':
                maskedHdu[0].header[cdKey] = maskedHdu[0].header[key] \
                    * maskedHdu[0].header['CDELT1']
            else:
                maskedHdu[0].header[cdKey] = maskedHdu[0].header[key] \
                    * maskedHdu[0].header['CDELT2']
            maskedHdu[0].header.remove(key)

    # Shaving off excess pixels given bin size
    x_edge = np.shape(maskedHdu[0].data)[0] % block
    y_edge = np.shape(maskedHdu[0].data)[1] % block
    im_shape = np.shape(maskedHdu[0].data[x_edge:, y_edge:])

    # Reshape image array into arrays of block x block
    bin_im = np.reshape(maskedHdu[0].data[x_edge:, y_edge:],
                        (im_shape[0]//block,
                         block,
                         im_shape[1]//block,
                         block)
                        )

    binned = np.zeros((im_shape[0]//block, im_shape[1]//block))
    weight = np.zeros((im_shape[0]//block, im_shape[1]//block))
    for i in range(bin_im.shape[0]):
        for j in range(bin_im.shape[2]):
            box = bin_im[i, :, j, :]

            # Use clipped mean to mimic LSST
            bad = ~np.isfinite(box)
            clip = sigmaclip(box[~bad])
            binned[i, j] = np.mean(clip.clipped)
            weight[i, j] = len(box[~bad])/(block**2)

    # Transform WCS to the binned coordinate system
    bn_head = maskedHdu[0].header.copy()
    bn_head['CRPIX1'] = bn_head['CRPIX1']/block
    bn_head['CRPIX2'] = bn_head['CRPIX2']/block
    if 'CD1_1' in bn_head:
        bn_head['CD1_1'] = bn_head['CD1_1']*block
    if 'CD2_2' in bn_head:
        bn_head['CD2_2'] = bn_head['CD2_2']*block
    if 'CD1_2' in bn_head:
        bn_head['CD1_2'] = bn_head['CD1_2']*block
    if 'CD2_1' in bn_head:
        bn_head['CD2_1'] = bn_head['CD2_1']*block

    hdu = fits.PrimaryHDU(binned, header=bn_head)
    binnedHdu = fits.HDUList([hdu])

    return binnedHdu, weight


def maskToLimit(imageNoSky, sbLim, magZp, pxScale=0.168):
    '''
    Creates an object mask out to a specified surface brightness limit
        Parameters
        ----------
        imageNoSky : `astropy.io.fits.hdu.image.PrimaryHDU`
            Image with only objects; no noise or sky, BG 0 counts
        sbLim : `float`
            Surface brightness limit out to which to create masks
        magZp : `float`
            Zeropoint for converting from magnitudes to counts
        pxScale : `float`
            Pixel scale in arcsec per pixel

        Returns
        -------
        maskImage : `astropy.io.fits.hdu.image.PrimaryHDU`
            Boolean mask HDU, where True is masked and False is not
    '''
    # Converting surface brightness to counts
    countLim = 10**(-0.4*(sbLim - magZp - 2.5*np.log10(pxScale**2)))
    mask = imageNoSky[0].data >= countLim
    mask = np.array(mask, dtype=int)
    maskImage = makeHduList(mask)

    return maskImage


def legendreSkySub(polyOrder, maskedImage, bnFac, maskVal=np.nan, full=False):
    '''
    Models and subtracts the sky using Legendre polynomials
        Parameters
        ----------
        polyOrder : `int`
            Order of desired Legendre polynomial fit to the image background
        maskedImage : `astropy.io.fits.hdu.image.PrimaryHDU`
            HDUList of input image, with mask applied via maskVal
        bnFac : `int`
            Binning factor to be applied to maskedImage before fitting sky
        maskVal : `float`
            Pixel value corresponding to mask in maskedImage
            (Defaults to np.nan)
        full : `bool`
            If True, returns the parameters of the fit as well

        Returns
        -------
        skyModel : `numpy.ndarray`
            Best-fit sky model image, at native resolution
        m : `astropy.modeling.FittableModel`
            Model fit with full parameters (accessed via m.c0_0, m.c1_0, etc.)
    '''
    assert type(maskedImage) == fits.hdu.hdulist.HDUList, \
        'Input masked image must be an HDUList, with a header'
    assert (polyOrder >= 0), \
        'Polynomial order must be 0 or positive'
    assert (bnFac > 0), \
        'Bin factor must be > 0'
    zeros = maskedImage[0].data == 0
    assert len(zeros[~zeros]) != 0, \
        'Image is all 0s; cannot hope to fit a blank image.'

    m_init = Legendre2D(polyOrder, polyOrder)
    fit = LevMarLSQFitter()

    try:
        binnedImage, weights = binImage(maskedImage, bnFac)
    except AssertionError:
        print('maskedImage must have a valid WCS header to bin!')
        return
    bnx = np.arange(bnFac//2+1, binnedImage[0].data.shape[1]*bnFac, bnFac)
    bny = np.arange(bnFac//2+1, binnedImage[0].data.shape[0]*bnFac, bnFac)
    bnX, bnY = np.meshgrid(bnx, bny)

    # Fitter can't handle np.nan; these are weighted 0.000
    binnedImage[0].data[np.isnan(binnedImage[0].data)] = -999

    # Fitting sky background using weight map
    x = np.arange(1, maskedImage[0].data.shape[1]+1)
    y = np.arange(1, maskedImage[0].data.shape[0]+1)
    X, Y = np.meshgrid(x, y)
    m = fit(m_init, bnX, bnY, binnedImage[0].data, weights=weights)
    skyModel = m(X, Y)

    if full:
        return skyModel, m

    else:
        return skyModel


def initialProcessing(imListFull, imListModels, maskMu,
                      polyOrder, bnFac, maskVal=np.nan, magZp=31.4):
    '''
    Masks, models the sky, and subtracts sky model from a single image.
        Parameters
        ----------
        fullImPath : `string`
            Full or partial path to image (models+sky+noise) on hard disk
        modelImPath : `string`
            Full or partial path to model-only image on hard disk
        maskMu : `float`
            Depth to draw masks, in units of surface brightness
        polyOrder : `int`
            Order of desired Legendre polynomial fit to the image background
        bnFac : `int`
            Binning factor to be applied to maskedImage before fitting sky
        maskVal : `float`
            Pixel value corresponding to mask in maskedImage
            (Defaults to np.nan)
        magZp : `float`
            Zeropoint to scale mask depth properly in flux

        Yields
        ------
        im : `astropy.io.fits.hdu.image.PrimaryHDU`
            Sky-subtracted image

    '''
    for i in range(len(imListFull)):
        print('Doing image ', i+1, ' of ', len(imListFull))
        im = fits.open(imListFull[i])
        maskIm = fits.open(imListFull[i])
        models = fits.open(imListModels[i])
        mask = maskToLimit(models, maskMu, magZp)
        maskIm[0].data[mask[0].data == 1] = np.nan
        skyModel = legendreSkySub(polyOrder, maskIm, bnFac, maskVal)
        im[0].data -= skyModel

        yield im


def coaddImages(raCen, decCen, size, im, pxScale=0.168,
                prefix='', outputDir='.', writeIms=False, expMap=False):
    '''
    Registers and median coadds all images using a blank reference image
        Parameters
        ----------
        raCen : `float`
            Central pixel reference right ascension, in decimal degrees
        decCen : `float`
            Central pixel reference declination, in decimal degrees
        size : `int`
            Width of blank image in pixels
        im : `generator`
            Generator produce by either initialProcessing() or
            finalProcessing()
        pxScale : `float`
            Pixel scale, in arcsec/px, for the blank image on which to register
            the other images
        prefix : `string`
            Image prefix appended to registered images if writeIms == True
        outputDir : `string`
            Path to directory in which to write registered image files if
            writeIms == True
        writeIms : `bool`
            If True, will write registered images to the disk in addition to
            the coadded image itself
        expMap : `bool`
            If True, will write out an image showing the number of exposures
            per pixel in the final coadd

        Returns
        -------
        coaddHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Images coadded onto the reference blankImage, with header
    '''
    assert type(prefix) == str
    assert type(outputDir) == str

    blankImage = makeBlankImage(raCen, decCen, size, pxScale)

    allIms = []
    # Doing full processing as part of the coaddition procedure
    for i, image in enumerate(im):
        assert (image[0].data.shape[1] < size) \
            & (image[0].data.shape[0] < size), \
            'Coadd size must be larger than image size!'
        offset_x = image[0].header['offsetx']
        offset_y = image[0].header['offsety']

        # Inject image into the right place on the blank image
        proj_im = blankImage[0].data * 0.0 + np.nan
        left_edge = (size//2) + offset_x - image[0].data.shape[1]//2
        right_edge = (size//2) + offset_x + image[0].data.shape[1]//2
        bottom_edge = (size//2) + offset_y - image[0].data.shape[0]//2
        top_edge = (size//2) + offset_y + image[0].data.shape[0]//2

        # Skip if the boundaries are off the coadd image box
        if (left_edge > size) | (bottom_edge > size):
            continue
        if (right_edge < 0) | (top_edge < 0):
            continue
        # Resize otherwise
        if (left_edge < 0) & (right_edge > 0):
            image[0].data = image[0].data[:, np.abs(left_edge):]
            left_edge = 0
        if (right_edge > size) & (left_edge < size):
            image[0].data = image[0].data[:, : -(right_edge - size)]
            right_edge = size
        if (bottom_edge < 0) & (top_edge > 0):
            image[0].data = image[0].data[np.abs(bottom_edge):, :]
            bottom_edge = 0
        if (top_edge > size) & (bottom_edge < size):
            image[0].data = image[0].data[: -(top_edge - size), :]
            top_edge = size

        proj_im[bottom_edge: top_edge, left_edge: right_edge] = image[0].data
        del image

        # Yes, this runs into memory issues if you use too many images or too
        # large a coadd size.
        allIms.append(proj_im)
        if writeIms:
            writeImHead(proj_im, blankImage[0].header,
                        outputDir+'/'+prefix+'fakes'+str(i)+'.fits')
        del proj_im

    print('Now median combining...')
    coadd = np.nanmedian(allIms, axis=0, overwrite_input=True)
    hdu = fits.PrimaryHDU(coadd, header=blankImage[0].header)
    coaddHdu = fits.HDUList([hdu])

    if expMap:
        for im in allIms:
            im[np.isfinite(im)] = 1
        numObs = np.nansum(allIms, axis=0)
        numObs = makeHduList(numObs, header=coaddHdu[0].header)

        return coaddHdu, numObs

    else:
        return coaddHdu


def alignCropCoadd(image, coadd):
    '''
    Aligns and crops the coadd to the orientation and dimensions of an image
        Parameters
        ----------
        image : `astropy.io.fits.hdu.image.PrimaryHDU`
            Image from which the coadd is to be subtracted
        coadd : `astropy.io.fits.hdu.image.PrimaryHDU`
            The coadd to subtract from the image

        Returns
        -------
        reprojCoadd : `astropy.io.fits.hdu.image.PrimaryHDU`
            Coadd aligned to image and cropped to image dimensions, with
            image's header information copied
    '''
    assert type(image) == fits.hdu.hdulist.HDUList, \
        'Input image must be of type HDUList'
    assert type(coadd) == fits.hdu.hdulist.HDUList, \
        'Coadd image must be of type HDUList'

    # Setting up some quantities
    size = coadd[0].data.shape[0]  # Always a square
    image_x = image[0].data.shape[1]
    image_y = image[0].data.shape[0]
    offset = (image[0].header['offsetx'], image[0].header['offsety'])

    # Uses 0 order shift, as these all should be integers
    # Moves the image section to the coadd center
    reproj_coadd = ndimage.shift(coadd[0].data,
                                 [-offset[1], -offset[0]],
                                 order=0, cval=np.nan)
    # Then take only the center slice with the image dimensions
    if image_y % 2 == 0:
        reproj_coadd = reproj_coadd[size//2 - image_y//2: size//2 + image_y//2,
                                    size//2 - image_x//2: size//2 + image_x//2]
    # int(0.5) == 1 in Python, so odd numbers go up by 1
    else:
        reproj_coadd = reproj_coadd[size//2 - image_y//2:
                                    size//2 + image_y//2 + 1,
                                    size//2 - image_x//2:
                                    size//2 + image_x//2]

    reprojCoadd = makeHduList(reproj_coadd, image[0].header)
    return reprojCoadd


def coaddScaleFactor(imageHdu, croppedCoaddHdu, lowerBound, upperBound):
    '''
    Derives the flux scale factor to align coadd zeropoint with exposure
    zeropoint, by fitting a line within a certain range of flux, chosen by the
    user.  Advised to avoid the noise limit and steer clear of the non-linear
    regime.

        Parameters
        ----------
        imageHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Single exposure from which to subtract the coadd
        croppedCoaddHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Cropped and aligned coadd to subtract from the image
        lowerBound : `float`
            Lower fitting boundary for deriving scale factor, in counts
            Based on coadd, not imageHdu.
        upperBound : `float`
            Upper fitting boundary for deriving scale factor, in counts
            Based on coadd, not imageHdu.

        NOTE: lowerBound and upperBound are automatically adjusted by ~sky
        level in imageHdu.  This uses the sigma clipped image median.

        Returns
        -------
        scaleFac : `float`
            Amount by which to multiple the coadd before subtraction, to match
            to the individual exposure's zeropoint
    '''
    def segment(image):
        im_secs = {0: image[0: bound_y, 0: bound_x],
                   1: image[0: bound_y, bound_x:],
                   2: image[bound_y:, 0: bound_x],
                   3: image[bound_y:, bound_x:]}
        return im_secs

    # First get a rough estimate of the image's sky level
    clip = sigmaclip(imageHdu[0].data, 5, 5)
    sky = np.median(clip.clipped)

    # Next split the images into four quadrants and grab flux between bounds
    bound_x = imageHdu[0].data.shape[1]//2
    bound_y = imageHdu[0].data.shape[0]//2
    im_secs = segment(imageHdu[0].data)
    coadd_secs = segment(croppedCoaddHdu[0].data)
    # Now fit within the flux bounds in each segment
    slopes = []
    for sec in im_secs.keys():
        want_im = (im_secs[sec] <= upperBound + sky) \
            & (im_secs[sec] >= lowerBound + sky)
        want_coadd = (coadd_secs[sec] <= upperBound) \
            & (coadd_secs[sec] >= lowerBound)
        if len(coadd_secs[sec][want_im & want_coadd]) == 0:
            slopes.append(np.nan)
        else:
            fit = np.polyfit(coadd_secs[sec][want_im & want_coadd].flatten(),
                             im_secs[sec][want_im & want_coadd].flatten(),
                             1)
            slopes.append(fit[0])

    # Take the median of these as the appropriate scale factor
    scaleFac = np.nanmedian(slopes)

    return scaleFac


def subtractCoadd(image, reprojCoadd, scaleFac=1.0):
    '''
    Flux-scales and subtracts an aligned, cropped coadd from an image

        Parameters
        ----------
        image : `astropy.io.fits.hdu.image.PrimaryHDU`
            Image from which the coadd is to be subtracted
        coadd : `astropy.io.fits.hdu.image.PrimaryHDU`
            The coadd to subtract from the image
        scaleFac : `float`
            Amount by which to multiple the coadd before subtraction, to match
            to the individual exposure's zeropoint

        Returns
        -------
        diffHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            The coadd-subtracted image
    '''
    reprojCoadd[0].data *= scaleFac
    diffData = image[0].data - reprojCoadd[0].data

    diffHdu = makeHduList(diffData, header=image[0].header)

    return diffHdu


def expandEdges(binnedImage, width=4):
    padImage = np.pad(binnedImage, width, constant_values=np.nan)

    for y in range(binnedImage.shape[0]):
        slopeLeft = binnedImage[y, :][1] - binnedImage[y, :][0]
        slopeRight = binnedImage[y, :][-1] - binnedImage[y, :][-2]
        lineLeft = slopeLeft*np.arange(width) \
            + (binnedImage[y, :][0] - width*slopeLeft)
        lineRight = slopeRight*np.arange(width) \
            + (binnedImage[y, :][-1] + slopeRight)
        padImage[y+width, :width] = lineLeft
        padImage[y+width, -width:] = lineRight

    for x in range(padImage.shape[1]):
        slopeDown = padImage[width:-width, x][1] \
            - padImage[width:-width, x][0]
        slopeUp = padImage[width:-width, x][-1] \
            - padImage[width:-width, x][-2]
        lineDown = slopeDown*np.arange(width) \
            + (padImage[width:-width, x][0] - width*slopeDown)
        lineUp = slopeUp*np.arange(width) \
            + (padImage[width:-width, x][-1] + slopeUp)
        padImage[:width, x] = lineDown
        padImage[-width:, x] = lineUp

    return padImage


def makeSkyMapBinning(skyImage, binnedHdu, sigma=1.0, block=16):
    '''
    Fills flux in binned image across masks using inpainting, applies a lowpass
    filter, then enlarges image to original size.
    This is an order of magnitude faster than simply applying a Gaussian filter
    across the native resolution image, but produces similar results.
        Parameters
        ----------
        skyImage : `astropy.io.fits.hdu.image.PrimaryHDU`
            The standard resolution coadd-subtracted image HDUList
        binnedHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Masked, binned image HDUList to be inpainted
        sigma : `float`
            Standard deviation of Gaussian kernel used for lowpass filtering
        block : `int`
            Binning factor in pixels

        Returns
        -------
        skyMap : `astropy.io.fits.hdu.image.PrimaryHDU`
            Smooth, mostly noiseless version of skyImage
    '''
    assert type(skyImage) == fits.hdu.hdulist.HDUList, \
        'Input image must be of type HDUList'
    assert type(binnedHdu) == fits.hdu.hdulist.HDUList, \
        'Input binned image must be of type HDUList'
    assert sigma > 0, 'Gaussian kernel standard deviation must be positive'
    assert block > 0, 'Bin factor must be positive'
    assert np.round(block, 0) == block, 'Bin factor must be an integer value'

    y_edge = np.shape(skyImage[0].data)[0] % block
    x_edge = np.shape(skyImage[0].data)[1] % block
    if (x_edge != 0) | (y_edge != 0):
        print('Warning!  Image dimensions not evenly divisible by bin factor.')
        print('Strange things might occur at the image edges.')

    # Interpolate flux across masks using Inpainting technique
    # Adding a thick border to avoid edge effects from Gaussian smoothing later
    wid = 4
    padBin = expandEdges(binnedHdu[0].data, wid)
    bn_msk = np.isnan(padBin)
    if len(bn_msk[bn_msk]) != 0:
        binned = inpaint.inpaint_biharmonic(padBin, bn_msk)
    else:
        binned = padBin

    # Smooth the image
    binned = ndimage.gaussian_filter(binned, sigma, mode='constant',
                                     cval=np.nanmedian(binned))

    # Enlarged version of the binned image
    enlarged_image = cv2.resize(binned,
                                (binned.shape[1]*block, binned.shape[0]*block),
                                interpolation=cv2.INTER_LINEAR)
    # Trim that expanded border away
    enlarged_image = enlarged_image[wid*block:-wid*block, wid*block:-wid*block]

    # Extrapolates missing pixel values from the binned image edges
    # Usually this doesn't do anything, if all works properly
    skyMap = np.zeros(skyImage[0].data.shape) + np.nan
    skyMap[y_edge:, x_edge:] = enlarged_image
    skyMap[:y_edge, :] = skyMap[y_edge:2*y_edge, :]
    skyMap[:, :x_edge] = skyMap[:, x_edge:2*x_edge]

    return skyMap


def finalProcessing(imListFull, imListModels, coaddHdu,
                    lowerBound, upperBound, block,
                    polyOrder,
                    sbLim=25, magZp=31.4, pxScale=0.168):
    '''
    Once initial coadd is created, generate new-generation sky-subtracted
    images with this.  Then use the generator this returns to remake the
    coadd.
        Parameters
        ----------
        imListFull : `list`
            List of full or partial paths to images to be processed
        imListModels : `list`
            List of full or partial paths to model-only images
        coaddHdu : `astropy.io.fits.hdu.image.PrimaryHDU`
            Initial coadd
        lowerBound : `float`
            Lower fitting boundary for deriving scale factor, in counts
            Based on coadd, not imageHdu.
        upperBound : `float`
            Upper fitting boundary for deriving scale factor, in counts
            Based on coadd, not imageHdu.
        block : `int`
            Bin factor to use when processing noisy sky frames
        polyOrder : `int`
            Order of polynomial used to fit sky map
        sbLim : `float`
            Limit for shallow masks, in units of surface brightness
        magZp : `float`
            Zeropoint to convert from surface brightness to counts
        pxScale : `float`
            Pixel scale in units of arcsec/px

        Yields
        ------
        newIm : `astropy.io.fits.hdu.image.PrimaryHDU`
            Image with revised coadd-subtraction sky removed
    '''
    for i in range(len(imListFull)):
        print('Doing image ', i+1, ' of ', len(imListFull))
        # Align and crop
        im = fits.open(imListFull[i])
        croppedCoadd = alignCropCoadd(im, coaddHdu)

        # Rescale flux
        scaleFac = coaddScaleFactor(im, croppedCoadd, lowerBound, upperBound)

        # Scale and subtract
        skyMapNoisy = subtractCoadd(im, croppedCoadd, scaleFac)

        # Create shallow mask for leftovers
        mask = maskToLimit(fits.open(imListModels[i]), sbLim, magZp, pxScale)
        skyMapNoisy[0].data[mask[0].data == 1] = np.nan

        # Process to remove artifacts and push down noise
        # binSky = binImage(skyMapNoisy, block)
        # skyMap = makeSkyMapBinning(skyMapNoisy, binSky, 1.0, block)
        # Alternative: fit a model to the coadd-subtracted images
        skyMap = legendreSkySub(polyOrder, skyMapNoisy, block)

        newIm = makeHduList(im[0].data - skyMap, im[0].header)

        yield newIm
